{
  "family": "central-llm-service",
  "networkMode": "bridge",
  "requiresCompatibilities": ["EC2"],
  "cpu": "6144",
  "memory": "20480",
  "executionRoleArn": "arn:aws:iam::396360117331:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::396360117331:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "vllm-server",
      "image": "396360117331.dkr.ecr.eu-central-1.amazonaws.com/llama31-8b-vllm:latest",
      "cpu": 6144,
      "memory": 20480,
      "essential": true,
      "portMappings": [
        {
          "containerPort": 8000,
          "hostPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "CUDA_VISIBLE_DEVICES",
          "value": "0"
        },
        {
          "name": "UVICORN_ACCESS_LOG",
          "value": "false"
        },
        {
          "name": "AUDIT_BUCKET",
          "value": "central-llm-audit"
        },
        {
          "name": "AUDIT_PREFIX",
          "value": "logs"
        },
        {
          "name": "AWS_REGION",
          "value": "eu-central-1"
        },
        {
          "name": "SERVED_MODEL_NAME",
          "value": "llama-3.1-8b-instruct"
        },
        {
          "name": "MAX_MODEL_LEN",
          "value": "32768"
        },
        {
          "name": "GPU_MEMORY_UTILIZATION",
          "value": "0.92"
        },
        {
          "name": "PYTORCH_CUDA_ALLOC_CONF",
          "value": "expandable_segments:True"
        },
        {
          "name": "LLAMA_ATTRIBUTION",
          "value": "Built with Llama"
        },
        {
          "name": "VLLM_READY_TIMEOUT",
          "value": "600"
        },
        {
          "name": "MAX_NUM_SEQS",
          "value": "64"
        },
        {
          "name": "MAX_NUM_BATCHED_TOKENS",
          "value": "40960"
        },
        {
          "name": "BLOCK_SIZE",
          "value": "16"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/central-llm-service",
          "awslogs-region": "eu-central-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": [
          "CMD-SHELL",
          "curl -f http://localhost:8000/health || exit 1"
        ],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 300
      },
      "resourceRequirements": [
        {
          "type": "GPU",
          "value": "1"
        }
      ],
      "ulimits": [
        {
          "name": "nofile",
          "softLimit": 65536,
          "hardLimit": 65536
        }
      ]
    }
  ]
}
